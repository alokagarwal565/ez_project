# 📚 Smart Research Assistant

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.0+-red.svg)](https://streamlit.io/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13+-blue.svg)](https://www.postgresql.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## 🚀 Overview

The **Smart Research Assistant** is an intelligent Streamlit application designed to help users interact with their documents using cutting-edge AI technology. It leverages **Retrieval Augmented Generation (RAG)** and **Google's Gemini Large Language Models** to provide powerful document analysis capabilities.

Users can upload various document types (PDF, TXT, CSV), which are then processed and stored in a **PGVector database** for efficient retrieval. This enables powerful semantic search and AI-driven insights directly from your research materials.

## ✨ Features

- **📄 Document Upload**: Easily upload PDF, TXT, or CSV files to build your knowledge base
- **🧠 Intelligent Q&A (Ask Anything)**: Ask questions about your uploaded documents and get accurate answers generated by Gemini, with justifications referencing the original text
- **📝 Automatic Summarization**: Get concise summaries of your entire document content with a single click
- **💡 "Challenge Me" Mode**: Test your comprehension with logic-based, inference questions generated by Gemini from your documents. Get detailed evaluations of your answers, including accuracy, completeness, clarity, justification, and a score
- **🚀 PGVector Integration**: Utilizes PostgreSQL with the `pgvector` extension for efficient storage and retrieval of document embeddings
- **⚡ HNSW Indexing**: Improves vector search performance in the database for faster responses
- **🔧 Modular Design**: Cleanly separated concerns for configuration, RAG pipeline, challenge mode, and utility functions

## 🛠️ Technical Stack

| Component | Technology |
|-----------|------------|
| **Frontend** | Streamlit |
| **Backend Logic** | Python |
| **Large Language Model** | Google Gemini (`gemini-1.5-flash-latest`) |
| **Embedding Model** | HuggingFace Sentence Transformers (`all-MiniLM-L6-v2`) |
| **Vector Database** | PostgreSQL with PGVector extension |
| **Document Processing** | LangChain, PyPDF, Pandas |

## 📋 Prerequisites

Before you begin, ensure you have the following installed:

- **Python 3.9+**
- **Docker** (recommended for PostgreSQL setup) or a local PostgreSQL installation
- **Google API Key** for Gemini

## 🔧 Setup and Installation

### Step 1: Clone the Repository

```bash
git clone https://github.com/your-username/smart-research-assistant.git
cd smart-research-assistant
```

### Step 2: Set Up Environment Variables

Create a `.env` file in the root directory of the project and populate it with your credentials and database details:

```env
# Google API Key for Gemini
GOOGLE_API_KEY="YOUR_GEMINI_API_KEY"

# PostgreSQL Database Credentials
PG_USER="your_pg_user"
PG_PASSWORD="your_pg_password"
PG_HOST="localhost"
PG_PORT="5432"
PG_DBNAME="research_db"
```

> **⚠️ Important**: Replace the placeholder values with your actual credentials.

### Step 3: Set Up PostgreSQL with PGVector

#### Local PostgreSQL Installation

1. **Install PostgreSQL**: Follow instructions for your operating system
2. **Create a database and user**:
   ```sql
   CREATE USER your_pg_user WITH PASSWORD 'your_pg_password';
   CREATE DATABASE research_db OWNER your_pg_user;
   ```
3. **Install PGVector extension**:
   ```sql
   CREATE EXTENSION IF NOT EXISTS vector;
   ```

### Step 4: Install Python Dependencies

It's highly recommended to use a virtual environment:

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Step 5: Initialize the Database Schema

Run the initialization script to create the necessary tables and vector extension:

```bash
python src/init_db.py
```

You should see log messages indicating successful table creation and extension enabling.

### Step 6: Run the Streamlit Application

Navigate to the src directory and run the main application:

```bash
streamlit run src/main.py
```

Your web browser should automatically open the Streamlit application. If not, open your browser and go to `http://localhost:8501`.

## 🎯 Usage

### 1. Upload Documents
- On the sidebar, use the "Upload Document" section to upload your `.pdf`, `.txt`, or `.csv` files
- Once uploaded, the application will process the document, chunk it, embed it, and store it in the PGVector database
- An automatic summary will also be generated and displayed

### 2. Ask Anything (RAG Q&A)
- Select the "Ask Anything" tab
- Type your question in the text area and press Enter or click "Get Answer"
- The AI will provide an answer based on the uploaded document, along with a justification and highlighted snippets

### 3. Auto Summary
- Select the "Auto Summary" tab
- If a document is processed, the automatic summary will be displayed here
- You can regenerate it if needed

### 4. Challenge Me
- Select the "Challenge Me" tab
- Click "Generate Challenge Questions" to get a set of comprehension-based questions related to your document
- Enter your answers in the provided text areas
- Click "Evaluate My Answers" to receive detailed feedback, including accuracy, completeness, clarity, justification, and a score for each of your answers

## 📁 Project Structure

```
.
├── data/                      # Temporarily stores uploaded documents
├── src/
│   ├── challenge_mode.py      # Logic for generating and evaluating challenge questions
│   ├── config.py              # Centralized configuration settings
│   ├── helpers.py             # Utility functions (e.g., cosine similarity, download button, HNSW indexing)
│   ├── init_db.py             # Script to initialize PostgreSQL database schema
│   ├── main.py                # Main Streamlit application entry point and UI orchestration
│   ├── prompt_templates.py    # Stores various prompt templates for LLM tasks
│   └── rag_pipeline.py        # Core RAG functionalities: document loading, chunking, embedding, vector DB, RAG chain, summarization
├── .env                       # Environment variables (Google API Key, DB credentials)
├── docker-compose.yml         # Optional: Docker Compose for PostgreSQL
├── requirements.txt           # Python dependencies
└── README.md                  # This file
```

## 🤝 Contributing

Contributions are welcome! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

Please make sure to update tests as appropriate and follow the existing code style.

## 📝 License

This project is open-source and available under the [MIT License](https://opensource.org/licenses/MIT).

## 🆘 Support

If you encounter any problems or have questions, please:

1. Check the [Issues](https://github.com/your-username/smart-research-assistant/issues) page
2. Create a new issue if your problem isn't already reported
3. Provide detailed information about your setup and the error you're experiencing

## 🙏 Acknowledgments

- [Google Gemini](https://deepmind.google/technologies/gemini/) for the powerful language model
- [Streamlit](https://streamlit.io/) for the amazing web framework
- [PGVector](https://github.com/pgvector/pgvector) for efficient vector storage
- [LangChain](https://python.langchain.com/) for the RAG pipeline components

---

**Made with ❤️ by [Alok Agarwal]**